# æµ‹è¯•è¯­ä¹‰RAGç³»ç»Ÿ
# éªŒè¯æ–°çš„å‘é‡åŒ–è¯­ä¹‰æ£€ç´¢åŠŸèƒ½

import asyncio
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))
from agents.knowledge_base.orchestrator_agent import OrchestratorAgent

async def test_semantic_rag():
    """æµ‹è¯•è¯­ä¹‰RAGç³»ç»Ÿ"""
    print("=" * 80)
    print("    è¯­ä¹‰RAGç³»ç»Ÿæµ‹è¯•")
    print("=" * 80)

    # --- 1. åˆå§‹åŒ–ç³»ç»Ÿï¼ˆå¯ç”¨è¯­ä¹‰æœç´¢ï¼‰---
    llm_config = {
        'provider': 'ollama',
        'model': 'deepseek-r1:latest',
        'use_semantic_search': True  # å¯ç”¨è¯­ä¹‰æœç´¢
    }
    orchestrator = OrchestratorAgent(llm_config=llm_config)

    # --- 2. æ·»åŠ æµ‹è¯•çŸ¥è¯† ---
    print("\n--- æ­¥éª¤1: æ·»åŠ çŸ¥è¯†åˆ°è¯­ä¹‰æœç´¢ç³»ç»Ÿ ---")
    knowledge_data = {
        "sources": [
            # ç›¸ä¼¼æ¦‚å¿µçš„ä¸åŒè¡¨è¾¾
            {"type": "text", "location": "å¤ªé˜³æ˜¯æ’æ˜Ÿï¼Œè¡¨é¢æ¸©åº¦çº¦5778å¼€å°”æ–‡ã€‚", "metadata": {"category": "astronomy"}},
            {"type": "text", "location": "æ’æ˜Ÿè¡¨é¢çš„çƒ­åº¦å¤§çº¦æ˜¯5778Kã€‚", "metadata": {"category": "astronomy"}},
            
            {"type": "text", "location": "H2Oæ˜¯æ°´çš„åŒ–å­¦ç¬¦å·ã€‚", "metadata": {"category": "chemistry"}},
            {"type": "text", "location": "æ°´åˆ†å­ç”±æ°¢æ°§åŸå­æ„æˆã€‚", "metadata": {"category": "chemistry"}},
            
            {"type": "text", "location": "åœ†å½¢åŒºåŸŸçš„å¤§å°ç”¨Ï€rÂ²è®¡ç®—ã€‚", "metadata": {"category": "math"}},
            {"type": "text", "location": "åœ†çš„é¢ç§¯ç­‰äºÏ€ä¹˜ä»¥åŠå¾„çš„å¹³æ–¹ã€‚", "metadata": {"category": "math"}},
            
            {"type": "text", "location": "é€Ÿç‡ç­‰äºè·¯ç¨‹é™¤ä»¥æ—¶é—´ã€‚", "metadata": {"category": "physics"}},
            {"type": "text", "location": "v=s/tæ˜¯é€Ÿåº¦çš„è®¡ç®—å…¬å¼ã€‚", "metadata": {"category": "physics"}},
            
            # é€»è¾‘æ¨ç†ç›¸å…³
            {"type": "text", "location": "å¦‚æœå‰ææˆç«‹ï¼Œç»“è®ºå¿…ç„¶æˆç«‹ï¼Œè¿™å«è‚¯å®šå‰ä»¶ã€‚", "metadata": {"category": "logic"}},
            {"type": "text", "location": "å½“æ¡ä»¶ä¸ºçœŸæ—¶ï¼Œç»“æœä¹Ÿä¸ºçœŸçš„æ¨ç†æ–¹å¼ã€‚", "metadata": {"category": "logic"}},
        ]
    }
    
    result = await orchestrator.receive_request(
        source="user",
        request_type="add_knowledge",
        payload=knowledge_data
    )
    print(f"çŸ¥è¯†æ·»åŠ ç»“æœ: {result['message']}")
    print(f"å¤„ç†çš„çŸ¥è¯†å—æ•°é‡: {result['chunks_count']}")

    # --- 3. æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼æ€§æ£€ç´¢ ---
    print("\n--- æ­¥éª¤2: æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼æ€§æ£€ç´¢ ---")
    
    test_cases = [
        {
            "query": "æ’æ˜Ÿçš„æ¸©åº¦æ˜¯å¤šå°‘ï¼Ÿ",
            "expected_concept": "å¤ªé˜³æ¸©åº¦",
            "description": "æµ‹è¯•åŒä¹‰è¯åŒ¹é…ï¼ˆæ’æ˜Ÿ vs å¤ªé˜³ï¼‰"
        },
        {
            "query": "æ°´çš„åˆ†å­ç»„æˆæ˜¯ä»€ä¹ˆï¼Ÿ", 
            "expected_concept": "æ°´åˆ†å­ç»“æ„",
            "description": "æµ‹è¯•æ¦‚å¿µç›¸ä¼¼æ€§ï¼ˆåˆ†å­ç»„æˆ vs åŒ–å­¦ç¬¦å·ï¼‰"
        },
        {
            "query": "å¦‚ä½•è®¡ç®—åœ†çš„å¤§å°ï¼Ÿ",
            "expected_concept": "åœ†é¢ç§¯å…¬å¼", 
            "description": "æµ‹è¯•è¡¨è¾¾æ–¹å¼ç›¸ä¼¼æ€§ï¼ˆå¤§å° vs é¢ç§¯ï¼‰"
        },
        {
            "query": "è¿åŠ¨é€Ÿåº¦æ€ä¹ˆç®—ï¼Ÿ",
            "expected_concept": "é€Ÿåº¦å…¬å¼",
            "description": "æµ‹è¯•æ¦‚å¿µåŒ¹é…ï¼ˆè¿åŠ¨é€Ÿåº¦ vs é€Ÿåº¦ï¼‰"
        },
        {
            "query": "ä»€ä¹ˆæ˜¯æœ‰æ•ˆæ¨ç†ï¼Ÿ",
            "expected_concept": "é€»è¾‘æ¨ç†",
            "description": "æµ‹è¯•æŠ½è±¡æ¦‚å¿µåŒ¹é…ï¼ˆæœ‰æ•ˆæ¨ç† vs è‚¯å®šå‰ä»¶ï¼‰"
        }
    ]

    correct_matches = 0
    total_tests = len(test_cases)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n--- æµ‹è¯• {i}/{total_tests}: {test_case['description']} ---")
        print(f"æŸ¥è¯¢: {test_case['query']}")
        
        # æµ‹è¯•ä¸åŒçš„æ£€ç´¢æ–¹æ³•
        for method in ['semantic', 'hybrid']:
            print(f"\nä½¿ç”¨ {method} æ£€ç´¢æ–¹æ³•:")
            
            query_payload = {
                "query": test_case['query'],
                "search_params": {
                    "top_k": 2,
                    "filters": {
                        "retrieval_method": method
                    }
                }
            }
            
            try:
                query_result = await orchestrator.receive_request(
                    source="user",
                    request_type="query",
                    payload=query_payload
                )
                
                answer = query_result['answer']
                sources = query_result['retrieved_sources']
                
                print(f"ç­”æ¡ˆ: {answer}")
                print(f"æ£€ç´¢åˆ° {len(sources)} ä¸ªç›¸å…³æº")
                
                # æ˜¾ç¤ºæ£€ç´¢åˆ°çš„æºå’Œç›¸ä¼¼åº¦åˆ†æ•°
                for j, source in enumerate(sources):
                    print(f"  æº {j+1}: {source['content'][:50]}... (ç›¸ä¼¼åº¦: {source['relevance_score']:.3f})")
                
                # ç®€å•çš„è´¨é‡è¯„ä¼°
                if len(answer) > 15 and "æ²¡æœ‰æ‰¾åˆ°" not in answer:
                    if i == 1:  # åªåœ¨ç¬¬ä¸€æ¬¡è®¡ç®—æ­£ç¡®åŒ¹é…æ•°
                        correct_matches += 1
                    print(f"âœ… {method} æ£€ç´¢è´¨é‡: è‰¯å¥½")
                else:
                    print(f"âŒ {method} æ£€ç´¢è´¨é‡: éœ€è¦æ”¹è¿›")
                    
            except Exception as e:
                print(f"âŒ {method} æ£€ç´¢å¤±è´¥: {str(e)}")

    # --- 4. å¯¹æ¯”æµ‹è¯•ï¼šå…³é”®è¯ vs è¯­ä¹‰æ£€ç´¢ ---
    print(f"\n--- æ­¥éª¤3: å¯¹æ¯”ä¸åŒæ£€ç´¢æ–¹æ³• ---")
    
    comparison_query = "æ˜Ÿçƒçš„çƒ­åº¦"  # è¿™ä¸ªæŸ¥è¯¢åº”è¯¥åŒ¹é…"å¤ªé˜³æ¸©åº¦"ç›¸å…³å†…å®¹
    print(f"å¯¹æ¯”æŸ¥è¯¢: {comparison_query}")
    
    for method in ['keyword', 'semantic', 'hybrid']:
        print(f"\n{method.upper()} æ£€ç´¢ç»“æœ:")
        
        query_payload = {
            "query": comparison_query,
            "search_params": {
                "top_k": 3,
                "filters": {
                    "retrieval_method": method
                }
            }
        }
        
        try:
            query_result = await orchestrator.receive_request(
                source="user",
                request_type="query", 
                payload=query_payload
            )
            
            sources = query_result['retrieved_sources']
            print(f"æ£€ç´¢åˆ° {len(sources)} ä¸ªæº:")
            
            for j, source in enumerate(sources):
                print(f"  {j+1}. {source['content']} (åˆ†æ•°: {source['relevance_score']:.3f})")
                
        except Exception as e:
            print(f"âŒ {method} æ£€ç´¢å¤±è´¥: {str(e)}")

    # --- 5. æµ‹è¯•ç»“æœç»Ÿè®¡ ---
    print("\n" + "=" * 80)
    print("    è¯­ä¹‰RAGæµ‹è¯•ç»“æœç»Ÿè®¡")
    print("=" * 80)
    print(f"æ€»æµ‹è¯•ç”¨ä¾‹: {total_tests}")
    print(f"æˆåŠŸåŒ¹é…: {correct_matches}")
    print(f"æˆåŠŸç‡: {correct_matches/total_tests*100:.1f}%")
    
    if correct_matches >= total_tests * 0.8:
        print("\nğŸ‰ è¯­ä¹‰æ£€ç´¢æµ‹è¯•ç»“æœ: ä¼˜ç§€!")
        print("âœ… ç³»ç»Ÿèƒ½å¤Ÿç†è§£è¯­ä¹‰ç›¸ä¼¼æ€§")
        print("âœ… æ”¯æŒåŒä¹‰è¯å’Œæ¦‚å¿µåŒ¹é…")
        print("âœ… æä¾›å¤šç§æ£€ç´¢ç­–ç•¥")
    elif correct_matches >= total_tests * 0.6:
        print("\nğŸ‘ è¯­ä¹‰æ£€ç´¢æµ‹è¯•ç»“æœ: è‰¯å¥½")
        print("âœ… åŸºæœ¬çš„è¯­ä¹‰ç†è§£èƒ½åŠ›")
        print("âš ï¸  éƒ¨åˆ†å¤æ‚æ¦‚å¿µåŒ¹é…éœ€è¦æ”¹è¿›")
    else:
        print("\nâš ï¸  è¯­ä¹‰æ£€ç´¢æµ‹è¯•ç»“æœ: éœ€è¦æ”¹è¿›")
        print("âŒ è¯­ä¹‰ç†è§£èƒ½åŠ›æœ‰é™")
        print("ğŸ’¡ å»ºè®®ä¼˜åŒ–åµŒå…¥å‘é‡ç®—æ³•")

    print("\n--- è¯­ä¹‰RAGæµ‹è¯•å®Œæˆ ---")

if __name__ == "__main__":
    asyncio.run(test_semantic_rag())